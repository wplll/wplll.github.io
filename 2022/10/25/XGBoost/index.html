<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="w_pl"><meta name="copyright" content="w_pl"><meta name="generator" content="Hexo 5.4.2"><meta name="theme" content="hexo-theme-yun"><title>XGBoost实战 | wpl'web</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/star-markdown-css@0.4.1/dist/yun/yun-markdown.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/prism-theme-vars/base.css"><script src="https://fastly.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".markdown-body img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script type="module">import { renderKatex } from '/js/utils.js'
document.addEventListener("DOMContentLoaded", () => {
  renderKatex({
    ...{},
    ...true?.options,
  });
});</script><link rel="icon" type="image/svg+xml" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="preconnect" href="https://fastly.jsdelivr.net/npm/" crossorigin><script id="yun-config">
    window.Yun = {}
    window.CONFIG = {"hostname":"wplll.github.io","root":"/","title":"wpl'web","version":"1.10.9","mode":"time","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}.","hits":"${hits} results found","hits_time":"${hits} results found in ${time} ms"},"anonymous_image":"https://cdn.yunyoujun.cn/img/avatar/none.jpg","say":{"api":"https://el-bot-api.vercel.app/api/words/young"},"fireworks":{"colors":null},"vendors":{"host":"https://fastly.jsdelivr.net/npm/","darken":"https://fastly.jsdelivr.net/npm/darken@1.5.0"}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/hexo-theme-yun.js" type="module"></script><meta name="description" content="1234567891011from xgboost import XGBRegressor as XGBRfrom sklearn.ensemble import RandomForestRegressor as RFRfrom sklearn.linear_model import LinearRegression as LinearRfrom sklearn.datasets import l">
<meta property="og:type" content="article">
<meta property="og:title" content="XGBoost实战">
<meta property="og:url" content="https://wplll.github.io/2022/10/25/XGBoost/index.html">
<meta property="og:site_name" content="wpl&#39;web">
<meta property="og:description" content="1234567891011from xgboost import XGBRegressor as XGBRfrom sklearn.ensemble import RandomForestRegressor as RFRfrom sklearn.linear_model import LinearRegression as LinearRfrom sklearn.datasets import l">
<meta property="og:locale">
<meta property="og:image" content="https://wplll.github.io/images/xgb_1.png">
<meta property="og:image" content="https://wplll.github.io/images/xgb_2.png">
<meta property="og:image" content="https://wplll.github.io/images/xgb_3.png">
<meta property="og:image" content="https://wplll.github.io/images/xgb_4.png">
<meta property="og:image" content="https://wplll.github.io/images/xgb_5.png">
<meta property="og:image" content="https://wplll.github.io/images/xgb_6.png">
<meta property="og:image" content="https://wplll.github.io/images/xgb_7.png">
<meta property="article:published_time" content="2022-10-25T07:37:56.647Z">
<meta property="article:modified_time" content="2022-10-25T15:39:31.972Z">
<meta property="article:author" content="w_pl">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wplll.github.io/images/xgb_1.png"><script>(function() {
  if (CONFIG.mode !== 'auto') return
  const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
  const setting = localStorage.getItem('darken-mode') || 'auto'
  if (setting === 'dark' || (prefersDark && setting !== 'light'))
    document.documentElement.classList.toggle('dark', true)
})()</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head><body><script src="https://code.iconify.design/2/2.1.1/iconify.min.js"></script><script>// Define global variable
IconifyProviders = {
  // Empty prefix: overwrite default API provider configuration
  '': {
    // Use custom API first, use Iconify public API as backup
    resources: [
        'https://api.iconify.design',
    ],
    // Wait for 1 second before switching API hosts
    rotate: 1000,
  },
};</script><script defer src="https://fastly.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js" type="module"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js" type="module"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="Table of Contents"><span class="icon iconify" data-icon="ri:list-ordered"></span></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="Overview"><span class="icon iconify" data-icon="ri:passport-line"></span></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info mickey-mouse"><a class="site-author-avatar" href="/about/" title="w_pl"><img width="96" loading="lazy" src="/images/1.jpg" alt="w_pl"></a><div class="site-author-name"><a href="/about/">w_pl</a></div><span class="site-name">wpl'web</span><sub class="site-subtitle">沉沦虚调 懊丧无声</sub><div class="site-description"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="Home"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:home-4-line"></span></span></a><div class="site-state-item"><a href="/archives/" title="Archives"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:archive-line"></span></span><span class="site-state-item-count">2</span></a></div><div class="site-state-item"><a href="/categories/" title="Categories"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:folder-2-line"></span></span><span class="site-state-item-count">0</span></a></div><div class="site-state-item"><a href="/tags/" title="Tags"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="site-state-item-count">0</span></a></div><a class="site-state-item hty-icon-button" href="https://wplll.github.io" title="文档"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:settings-line"></span></span></a></nav><hr style="margin-bottom:0.5rem"><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><span class="icon iconify" data-icon="ri:genderless-line"></span></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><span class="icon iconify" data-icon="ri:contrast-2-line"></span></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E5%8F%82%E6%95%B0"><span class="toc-number">1.</span> <span class="toc-text">导入参数</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AF%B9%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83"><span class="toc-number">2.</span> <span class="toc-text">对模型进行训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%EF%BC%8C%E4%BD%BF%E7%94%A8%E6%B2%A1%E6%9C%89%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">交叉验证，使用没有训练的模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94"><span class="toc-number">4.</span> <span class="toc-text">模型对比</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%98%E5%88%B6%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF"><span class="toc-number">5.</span> <span class="toc-text">绘制学习曲线</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BF%9B%E8%A1%8C%E8%B0%83%E5%8F%82"><span class="toc-number">6.</span> <span class="toc-text">进行调参</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%98%E5%88%B6%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF%E8%A7%82%E5%AF%9Fn-estimators%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">6.1.</span> <span class="toc-text">绘制学习曲线观察n_estimators的影响</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B910-1010%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97"><span class="toc-number">6.1.1.</span> <span class="toc-text">对10~1010进行计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E4%B8%8E%E6%B3%9B%E5%8C%96%E8%AF%AF%E5%B7%AE"><span class="toc-number">6.1.2.</span> <span class="toc-text">方差与泛化误差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%86%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF%EF%BC%8C%E6%89%BE%E5%88%B0%E6%9C%80%E4%BD%B3n-estimators"><span class="toc-number">6.1.3.</span> <span class="toc-text">细化学习曲线，找到最佳n_estimators</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%89%E6%94%BE%E5%9B%9E%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7%EF%BC%8C%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0subsample"><span class="toc-number">6.2.</span> <span class="toc-text">有放回随机抽样，重要参数subsample</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3%E6%9C%89%E6%94%BE%E5%9B%9E%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7"><span class="toc-number">6.3.</span> <span class="toc-text">了解有放回随机抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9B%E8%A1%8C%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF%E5%88%86%E6%9E%90"><span class="toc-number">6.3.1.</span> <span class="toc-text">进行学习曲线分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%86n-estimators%E5%92%8Csubsample%E4%B8%80%E8%B5%B7%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E5%8F%96%E5%BE%97%E6%9C%80%E4%BC%98%E8%A7%A3"><span class="toc-number">6.3.2.</span> <span class="toc-text">将n_estimators和subsample一起进行训练取得最优解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%AD%E4%BB%A3%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%8C%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0eta"><span class="toc-number">6.4.</span> <span class="toc-text">迭代决策树，重要参数eta</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#XGBoost"><span class="toc-number">7.</span> <span class="toc-text">XGBoost</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%89%E6%8B%A9%E5%BC%B1%E8%AF%84%E4%BC%B0%E5%99%A8%EF%BC%9Abooster%E5%8F%82%E6%95%B0"><span class="toc-number">7.1.</span> <span class="toc-text">选择弱评估器：booster参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%EF%BC%9Aobjective"><span class="toc-number">7.2.</span> <span class="toc-text">目标函数：objective</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8sklearn%E8%BF%9B%E8%A1%8Cxgboost"><span class="toc-number">7.2.1.</span> <span class="toc-text">使用sklearn进行xgboost</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8xgboost%E5%BA%93"><span class="toc-number">7.2.2.</span> <span class="toc-text">使用xgboost库</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%B1%BBDMatrix%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number">7.2.2.0.1.</span> <span class="toc-text">使用类DMatrix读取数据</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%99%E6%98%8E%E5%8F%82%E6%95%B0"><span class="toc-number">7.2.2.1.</span> <span class="toc-text">写明参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BBtrain%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E5%AF%BC%E5%85%A5%E7%9A%84%E5%8F%82%E6%95%B0%E6%98%AF%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%A0%91%E7%9A%84%E6%95%B0%E9%87%8F%EF%BC%8C%E5%85%B6%E4%BB%96%E5%8F%82%E6%95%B0%E9%83%BD%E9%9C%80%E8%A6%81%E9%80%9A%E8%BF%87params%E6%9D%A5%E5%AF%BC%E5%85%A5"><span class="toc-number">7.2.2.2.</span> <span class="toc-text">类train，可以直接导入的参数是训练数据，树的数量，其他参数都需要通过params来导入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%8E%A5%E5%8F%A3"><span class="toc-number">7.2.2.3.</span> <span class="toc-text">使用接口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5sklearn%E5%BA%93%E8%BF%9B%E8%A1%8CR%E6%96%B9%E5%92%8C%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%E8%AF%84%E4%BC%B0"><span class="toc-number">7.2.2.4.</span> <span class="toc-text">导入sklearn库进行R方和均方误差评估</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article" style="--smc-primary:#0078E7;"><link itemprop="mainEntityOfPage" href="https://wplll.github.io/2022/10/25/XGBoost/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="w_pl"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="wpl'web"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">XGBoost实战</h1><div class="post-meta"><div class="post-time"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-line"></span></span> <time title="Created: 2022-10-25 15:37:56" itemprop="dateCreated datePublished" datetime="2022-10-25T15:37:56+08:00">2022-10-25</time></div><div class="post-classify"></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor <span class="keyword">as</span> XGBR</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor <span class="keyword">as</span> RFR</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression <span class="keyword">as</span> LinearR</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, cross_val_score <span class="keyword">as</span> CVS, train_test_split <span class="keyword">as</span> TTS</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error <span class="keyword">as</span> MSE</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> datetime</span><br></pre></td></tr></table></figure>

<h1 id="导入参数"><a href="#导入参数" class="headerlink" title="导入参数"></a>导入参数</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data = load_boston() <span class="comment"># 以波士顿房价为训练集</span></span><br><span class="line"></span><br><span class="line">x = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line">Xtrain,Xtest,Ytrain,Ytest = TTS(x,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">420</span>)</span><br></pre></td></tr></table></figure>

<h1 id="对模型进行训练"><a href="#对模型进行训练" class="headerlink" title="对模型进行训练"></a>对模型进行训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reg = XGBR(n_estimators=<span class="number">100</span>).fit(Xtrain,Ytrain) <span class="comment"># 参数实例化</span></span><br><span class="line">reg.predict(Xtest) <span class="comment"># 模型接口</span></span><br><span class="line"></span><br><span class="line">reg.score(Xtest,Ytest) <span class="comment"># 模型评估，r^2</span></span><br></pre></td></tr></table></figure>




<pre><code>0.9050988968414799
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MSE(Ytest,reg.predict(Xtest)) <span class="comment"># 均方误差</span></span><br></pre></td></tr></table></figure>




<pre><code>8.830916343629323
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.feature_importances_ <span class="comment">#模型重要性负数,每一个特征值的权重</span></span><br></pre></td></tr></table></figure>




<pre><code>array([0.01902167, 0.0042109 , 0.01478316, 0.00553537, 0.02222196,
       0.37914088, 0.01679686, 0.0469872 , 0.04073574, 0.05491759,
       0.06684221, 0.00869464, 0.3201119 ], dtype=float32)
</code></pre>
<h1 id="交叉验证，使用没有训练的模型"><a href="#交叉验证，使用没有训练的模型" class="headerlink" title="交叉验证，使用没有训练的模型"></a>交叉验证，使用没有训练的模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reg = XGBR(n_estimators=<span class="number">100</span>)</span><br><span class="line">CVS(reg,Xtrain,Ytrain,cv=<span class="number">5</span>).mean() <span class="comment"># 模型，数据，折数，得到交叉验证的评估指标 r^2</span></span><br></pre></td></tr></table></figure>




<pre><code>0.7995062821902295
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CVS(reg,Xtrain,Ytrain,cv=<span class="number">5</span>,scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>).mean() <span class="comment">#负均方误差</span></span><br></pre></td></tr></table></figure>




<pre><code>-16.215644229762717
</code></pre>
<h1 id="模型对比"><a href="#模型对比" class="headerlink" title="模型对比"></a>模型对比</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rfr = RFR(n_estimators=<span class="number">100</span>) <span class="comment"># 使用随机森林进行对比</span></span><br><span class="line">CVS(rfr,Xtrain,Ytrain,cv=<span class="number">5</span>).mean()</span><br></pre></td></tr></table></figure>




<pre><code>0.7977853495049871
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr = LinearR() <span class="comment"># 线性回归</span></span><br><span class="line">CVS(lr,Xtrain,Ytrain,cv=<span class="number">5</span>).mean()</span><br></pre></td></tr></table></figure>




<pre><code>0.6835070597278076
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reg = XGBR(n_estimators=<span class="number">10</span>,verbosity=<span class="number">0</span>) </span><br><span class="line">CVS(reg,Xtrain,Ytrain,cv=<span class="number">5</span>,scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>).mean()</span><br></pre></td></tr></table></figure>




<pre><code>-18.633733952333067
</code></pre>
<h1 id="绘制学习曲线"><a href="#绘制学习曲线" class="headerlink" title="绘制学习曲线"></a>绘制学习曲线</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_learning_curve</span>(<span class="params">estimator,title, X, y, </span></span><br><span class="line"><span class="params">                        ax=<span class="literal">None</span>, <span class="comment"># 选择子图</span></span></span><br><span class="line"><span class="params">                        ylim=<span class="literal">None</span>, <span class="comment"># 设置纵坐标的取值范围</span></span></span><br><span class="line"><span class="params">                        cv=<span class="literal">None</span>, <span class="comment"># 交叉验证</span></span></span><br><span class="line"><span class="params">                        n_jobs=<span class="literal">None</span> <span class="comment"># 设定索要使用的线程</span></span></span><br><span class="line"><span class="params">                       </span>):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> learning_curve</span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">    </span><br><span class="line">    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y</span><br><span class="line">                                                            ,shuffle=<span class="literal">True</span></span><br><span class="line">                                                            ,cv=cv</span><br><span class="line">                                                            ,random_state=<span class="number">420</span></span><br><span class="line">                                                            ,n_jobs=n_jobs)      </span><br><span class="line">    <span class="keyword">if</span> ax == <span class="literal">None</span>:</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ax = plt.figure()</span><br><span class="line">    ax.set_title(title)</span><br><span class="line">    <span class="keyword">if</span> ylim <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        ax.set_ylim(*ylim)</span><br><span class="line">    ax.set_xlabel(<span class="string">&quot;Training examples&quot;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&quot;Score&quot;</span>)</span><br><span class="line">    ax.grid() <span class="comment"># 绘制网格，不是必须</span></span><br><span class="line">    ax.plot(train_sizes, np.mean(train_scores, axis=<span class="number">1</span>), <span class="string">&#x27;o-&#x27;</span></span><br><span class="line">            , color=<span class="string">&quot;r&quot;</span>,label=<span class="string">&quot;Training score&quot;</span>)</span><br><span class="line">    ax.plot(train_sizes, np.mean(test_scores, axis=<span class="number">1</span>), <span class="string">&#x27;o-&#x27;</span></span><br><span class="line">            , color=<span class="string">&quot;g&quot;</span>,label=<span class="string">&quot;Test score&quot;</span>)</span><br><span class="line">    ax.legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> ax</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv = KFold(n_splits=<span class="number">5</span>,shuffle=<span class="literal">True</span>,random_state=<span class="number">42</span>)<span class="comment"># 交叉验证模式</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(XGBR(n_estimators=<span class="number">100</span>,random_state=<span class="number">420</span>),<span class="string">&quot;XGB&quot;</span>,Xtrain,Ytrain,ax=<span class="literal">None</span>,cv=cv)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/xgb_1.png" alt="png" loading="lazy"></p>
<h1 id="进行调参"><a href="#进行调参" class="headerlink" title="进行调参"></a>进行调参</h1><h2 id="绘制学习曲线观察n-estimators的影响"><a href="#绘制学习曲线观察n-estimators的影响" class="headerlink" title="绘制学习曲线观察n_estimators的影响"></a>绘制学习曲线观察n_estimators的影响</h2><h3 id="对10-1010进行计算"><a href="#对10-1010进行计算" class="headerlink" title="对10~1010进行计算"></a>对10~1010进行计算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">axisx = <span class="built_in">range</span>(<span class="number">10</span>,<span class="number">1010</span>,<span class="number">50</span>)</span><br><span class="line">rs = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> axisx:</span><br><span class="line">    reg = XGBR(n_estimators=i,random_state=<span class="number">420</span>)</span><br><span class="line">    rs.append(CVS(reg,Xtrain,Ytrain,cv=cv).mean())</span><br><span class="line"><span class="built_in">print</span>(axisx[rs.index(<span class="built_in">max</span>(rs))],<span class="built_in">max</span>(rs))</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(axisx,rs,c=<span class="string">&quot;red&quot;</span>,label=<span class="string">&quot;XGB&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>160 0.8320776498992342
</code></pre>
<p><img src="/images/xgb_2.png" alt="png" loading="lazy"></p>
<h3 id="方差与泛化误差"><a href="#方差与泛化误差" class="headerlink" title="方差与泛化误差"></a>方差与泛化误差</h3><p>泛化误差：E(f;D),方差：var,偏差：bias,噪声：ξ。<br><br>$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$<strong>E(f;D) &#x3D; bias² + var + ξ²</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">axisx = <span class="built_in">range</span>(<span class="number">50</span>,<span class="number">1050</span>,<span class="number">50</span>)</span><br><span class="line">rs = [] <span class="comment"># r^2</span></span><br><span class="line">var = [] <span class="comment"># 方差</span></span><br><span class="line">ge = [] <span class="comment"># 可控部分泛化误差</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> axisx:</span><br><span class="line">    reg = XGBR(n_estimators=i,random_state=<span class="number">420</span>)</span><br><span class="line">    cvresult = CVS(reg,Xtrain,Ytrain,cv=cv)</span><br><span class="line">    </span><br><span class="line">    rs.append(cvresult.mean()) <span class="comment"># 记录1-偏差,r^2   </span></span><br><span class="line">    var.append(cvresult.var()) <span class="comment"># 记录方差    </span></span><br><span class="line">    ge.append((<span class="number">1</span> - cvresult.mean())**<span class="number">2</span>+cvresult.var())<span class="comment"># 计算泛化误差的可控部分</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(axisx[rs.index(<span class="built_in">max</span>(rs))],<span class="built_in">max</span>(rs),var[rs.index(<span class="built_in">max</span>(rs))]) <span class="comment">#打印R2最高所对应的参数取值，并打印这个参数下的方差</span></span><br><span class="line"><span class="built_in">print</span>(axisx[var.index(<span class="built_in">min</span>(var))],rs[var.index(<span class="built_in">min</span>(var))],<span class="built_in">min</span>(var)) <span class="comment">#打印方差最低时对应的参数取值，并打印这个参数下的R2</span></span><br><span class="line"><span class="built_in">print</span>(axisx[ge.index(<span class="built_in">min</span>(ge))],rs[ge.index(<span class="built_in">min</span>(ge))],var[ge.index(<span class="built_in">min</span>(ge))],<span class="built_in">min</span>(ge)) <span class="comment">#打印泛化误差可控部分的参数取值，并打印这个参数下的R^2，方差以及泛化误差的可控部分</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(axisx,rs,c=<span class="string">&quot;red&quot;</span>,label=<span class="string">&quot;XGB&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>100 0.8320924293483107 0.005344212126112929
100 0.8320924293483107 0.005344212126112929
100 0.8320924293483107 0.005344212126112929 0.03353716440826495
</code></pre>
<p><img src="/images/xgb_3.png" alt="png" loading="lazy"></p>
<h3 id="细化学习曲线，找到最佳n-estimators"><a href="#细化学习曲线，找到最佳n-estimators" class="headerlink" title="细化学习曲线，找到最佳n_estimators"></a>细化学习曲线，找到最佳n_estimators</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">axisx = <span class="built_in">range</span>(<span class="number">50</span>,<span class="number">200</span>,<span class="number">10</span>) <span class="comment"># 将范围缩小</span></span><br><span class="line">rs = []</span><br><span class="line">var = []</span><br><span class="line">ge = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> axisx:</span><br><span class="line">    reg = XGBR(n_estimators=i,random_state=<span class="number">420</span>)</span><br><span class="line">    cvresult = CVS(reg,Xtrain,Ytrain,cv=cv)</span><br><span class="line">    </span><br><span class="line">    rs.append(cvresult.mean())</span><br><span class="line">    var.append(cvresult.var())</span><br><span class="line">    ge.append((<span class="number">1</span> - cvresult.mean())**<span class="number">2</span>+cvresult.var())</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(axisx[rs.index(<span class="built_in">max</span>(rs))],<span class="built_in">max</span>(rs),var[rs.index(<span class="built_in">max</span>(rs))])</span><br><span class="line"><span class="built_in">print</span>(axisx[var.index(<span class="built_in">min</span>(var))],rs[var.index(<span class="built_in">min</span>(var))],<span class="built_in">min</span>(var))</span><br><span class="line"><span class="built_in">print</span>(axisx[ge.index(<span class="built_in">min</span>(ge))],rs[ge.index(<span class="built_in">min</span>(ge))],var[ge.index(<span class="built_in">min</span>(ge))],<span class="built_in">min</span>(ge))</span><br><span class="line">rs = np.array(rs)</span><br><span class="line">var = np.array(var)*<span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># R^2线</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(axisx,rs,c=<span class="string">&quot;black&quot;</span>,label=<span class="string">&quot;XGB&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加方差线</span></span><br><span class="line">plt.plot(axisx,rs+var,c=<span class="string">&quot;red&quot;</span>,linestyle=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line">plt.plot(axisx,rs-var,c=<span class="string">&quot;red&quot;</span>,linestyle=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制泛化误差可控部分</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(axisx,ge,c=<span class="string">&quot;gray&quot;</span>,linestyle=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>100 0.8320924293483107 0.005344212126112929
100 0.8320924293483107 0.005344212126112929
100 0.8320924293483107 0.005344212126112929 0.03353716440826495
</code></pre>
<p><img src="/images/xgb_4.png" alt="png" loading="lazy"></p>
<p><img src="/images/xgb_5.png" alt="png" loading="lazy"></p>
<p>得到最佳取值为100。</p>
<h2 id="有放回随机抽样，重要参数subsample"><a href="#有放回随机抽样，重要参数subsample" class="headerlink" title="有放回随机抽样，重要参数subsample"></a>有放回随机抽样，重要参数subsample</h2><h2 id="了解有放回随机抽样"><a href="#了解有放回随机抽样" class="headerlink" title="了解有放回随机抽样"></a>了解有放回随机抽样<br></h2><p>$~~~~~~~$第一次随机从原始数据集中进行随机抽取，将其进行建模。把模型结果，即预测错误的样本反馈回原始数据集，增加其权重。然后循环此过程，不断修正之前判断错误的样本。一定程度上提升模型准度。<br><br>$~~~~~~~$在sklearn和xgboost中，使用subsample作为随机抽样参数，范围为(0，1]，默认为一，为抽取占原数据比例。</p>
<h3 id="进行学习曲线分析"><a href="#进行学习曲线分析" class="headerlink" title="进行学习曲线分析"></a>进行学习曲线分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">axisx = np.linspace(<span class="number">0.75</span>,<span class="number">1</span>,<span class="number">25</span>)<span class="comment"># 随机选取数值，多次调整，缩减范围</span></span><br><span class="line">rs = []</span><br><span class="line">var = []</span><br><span class="line">ge = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> axisx:</span><br><span class="line">    reg = XGBR(n_estimators=<span class="number">100</span>,subsample=i,random_state=<span class="number">420</span>)</span><br><span class="line">    cvresult = CVS(reg,Xtrain,Ytrain,cv=cv)</span><br><span class="line">    rs.append(cvresult.mean())</span><br><span class="line">    var.append(cvresult.var())</span><br><span class="line">    ge.append((<span class="number">1</span> - cvresult.mean())**<span class="number">2</span>+cvresult.var())</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(axisx[rs.index(<span class="built_in">max</span>(rs))],<span class="built_in">max</span>(rs),var[rs.index(<span class="built_in">max</span>(rs))])</span><br><span class="line"><span class="built_in">print</span>(axisx[var.index(<span class="built_in">min</span>(var))],rs[var.index(<span class="built_in">min</span>(var))],<span class="built_in">min</span>(var))</span><br><span class="line"><span class="built_in">print</span>(axisx[ge.index(<span class="built_in">min</span>(ge))],rs[ge.index(<span class="built_in">min</span>(ge))],var[ge.index(<span class="built_in">min</span>(ge))],<span class="built_in">min</span>(ge))</span><br><span class="line">rs = np.array(rs)</span><br><span class="line">var = np.array(var)</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(axisx,rs,c=<span class="string">&quot;black&quot;</span>,label=<span class="string">&quot;XGB&quot;</span>)</span><br><span class="line">plt.plot(axisx,rs+var,c=<span class="string">&quot;red&quot;</span>,linestyle=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line">plt.plot(axisx,rs-var,c=<span class="string">&quot;red&quot;</span>,linestyle=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>1.0 0.8320924293483107 0.005344212126112929
0.9375 0.8213387927010547 0.0023009355462403113
1.0 0.8320924293483107 0.005344212126112929 0.03353716440826495
</code></pre>
<p><img src="/images/xgb_6.png" alt="png" loading="lazy"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reg = XGBR(n_estimators=<span class="number">100</span>,subsample=<span class="number">0.9375</span>,random_state=<span class="number">420</span>).fit(Xtrain,Ytrain)</span><br><span class="line">reg.score(Xtest,Ytest)</span><br></pre></td></tr></table></figure>




<pre><code>0.9175041345374846
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MSE(Ytest,reg.predict(Xtest))</span><br></pre></td></tr></table></figure>




<pre><code>7.676560781152187
</code></pre>
<p>显然优于没有设置时的模型。如果模型准确率降低则取消使用此参数。</p>
<h3 id="将n-estimators和subsample一起进行训练取得最优解"><a href="#将n-estimators和subsample一起进行训练取得最优解" class="headerlink" title="将n_estimators和subsample一起进行训练取得最优解"></a>将n_estimators和subsample一起进行训练取得最优解</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">axisx_sub = np.linspace(<span class="number">0.75</span>,<span class="number">1</span>,<span class="number">25</span>)</span><br><span class="line">axisx_n_est = <span class="built_in">range</span>(<span class="number">50</span>,<span class="number">200</span>,<span class="number">10</span>)</span><br><span class="line">rs = []</span><br><span class="line">var = []</span><br><span class="line">ge = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> axisx_n_est:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> axisx_sub:</span><br><span class="line">        reg = XGBR(n_estimators=i,subsample=j,random_state=<span class="number">420</span>,eta=<span class="number">0.1</span>)</span><br><span class="line">        cvresult = CVS(reg,Xtrain,Ytrain,cv=cv)</span><br><span class="line">        rs.append(cvresult.mean())</span><br><span class="line">        var.append(cvresult.var())</span><br><span class="line">        ge.append((<span class="number">1</span> - cvresult.mean())**<span class="number">2</span>+cvresult.var())</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(axisx_n_est[<span class="built_in">int</span>(rs.index(<span class="built_in">max</span>(rs))/<span class="number">25</span>)],axisx_sub[rs.index(<span class="built_in">max</span>(rs))%<span class="number">25</span>],<span class="built_in">max</span>(rs),var[rs.index(<span class="built_in">max</span>(rs))])</span><br><span class="line"><span class="built_in">print</span>(axisx_n_est[<span class="built_in">int</span>(var.index(<span class="built_in">min</span>(var))/<span class="number">25</span>)],axisx_sub[var.index(<span class="built_in">min</span>(var))%<span class="number">25</span>],rs[var.index(<span class="built_in">min</span>(var))],<span class="built_in">min</span>(var))</span><br><span class="line"><span class="built_in">print</span>(axisx_n_est[<span class="built_in">int</span>(ge.index(<span class="built_in">min</span>(ge))/<span class="number">25</span>)],axisx_sub[ge.index(<span class="built_in">min</span>(ge))%<span class="number">25</span>],rs[ge.index(<span class="built_in">min</span>(ge))],var[ge.index(<span class="built_in">min</span>(ge))],<span class="built_in">min</span>(ge))</span><br></pre></td></tr></table></figure>

<pre><code>160 0.9583333333333333 0.8432917907566264 0.004614845818885538
50 0.9479166666666666 0.8339831443137825 0.003529311838690004
190 0.9479166666666666 0.842287142171737 0.004044787817216516 0.028918133341574434
</code></pre>
<h2 id="迭代决策树，重要参数eta"><a href="#迭代决策树，重要参数eta" class="headerlink" title="迭代决策树，重要参数eta"></a>迭代决策树，重要参数eta<br></h2><p>参数eta为迭代决策树的步长。<br><br>迭代树公式为：<br><br>$~~~~~~~~~~~~~~~~~~~~~~~~~$ $y_i^{k+1} &#x3D; y_i^k + ŋf_{k+1}^{x_i}$<br><br>eta即为ŋ，也称为学习率，取值范围为[0,1]。在xgboost中默认为0.3，在sklearn中为0.1。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 评分函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">regassess</span>(<span class="params">reg,Xtrain,Ytrain,cv,scoring = [<span class="string">&quot;r^2&quot;</span>],show=<span class="literal">True</span></span>):</span><br><span class="line">    score = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(scoring)):</span><br><span class="line">        <span class="keyword">if</span> show:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;:&#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(scoring[i] <span class="comment">#模型评估指标的名字</span></span><br><span class="line">                                     ,CVS(reg</span><br><span class="line">                                          ,Xtrain,Ytrain</span><br><span class="line">                                          ,cv=cv,scoring=scoring[i]).mean()))</span><br><span class="line">        score.append(CVS(reg,Xtrain,Ytrain,cv=cv,scoring=scoring[i]).mean())</span><br><span class="line">    <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">axisx = np.arange(<span class="number">0.05</span>,<span class="number">1</span>,<span class="number">0.05</span>)</span><br><span class="line">rs = []</span><br><span class="line">te = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> axisx:</span><br><span class="line">    reg = XGBR(n_estimators=<span class="number">100</span>,subsample=<span class="number">0.9375</span>,random_state=<span class="number">420</span>,learning_rate=i)</span><br><span class="line">    score = regassess(reg,Xtrain,Ytrain,cv,scoring = [<span class="string">&quot;r2&quot;</span>,<span class="string">&quot;neg_mean_squared_error&quot;</span>],show=<span class="literal">False</span>)</span><br><span class="line">    test = reg.fit(Xtrain,Ytrain).score(Xtest,Ytest)</span><br><span class="line">    rs.append(score[<span class="number">0</span>])</span><br><span class="line">    te.append(test)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(axisx[rs.index(<span class="built_in">max</span>(rs))],<span class="built_in">max</span>(rs))</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(axisx,te,c=<span class="string">&quot;gray&quot;</span>,label=<span class="string">&quot;test&quot;</span>)</span><br><span class="line">plt.plot(axisx,rs,c=<span class="string">&quot;green&quot;</span>,label=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>0.35000000000000003 0.8398273910404873
</code></pre>
<p><img src="/images/xgb_7.png" alt="png" loading="lazy"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reg = XGBR(n_estimators=<span class="number">100</span>,subsample=<span class="number">0.9375</span>,random_state=<span class="number">420</span>,eta=<span class="number">0.35</span>).fit(Xtrain,Ytrain)</span><br><span class="line">reg.score(Xtest,Ytest)</span><br></pre></td></tr></table></figure>




<pre><code>0.8948044049000868
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MSE(Ytest,reg.predict(Xtest))</span><br></pre></td></tr></table></figure>




<pre><code>9.78885881330489
</code></pre>
<p>发现并没有提升，反而下降。eta一般作为模型训练时间的调整指标，如果模型没有错误，一般都会收敛，eta影响并不算大。根据训练经验，eta取值一般在0.1左右</p>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost<br></h1><h2 id="选择弱评估器：booster参数"><a href="#选择弱评估器：booster参数" class="headerlink" title="选择弱评估器：booster参数"></a>选择弱评估器：booster参数<br></h2><p>$ ~~~~~~ $在sklearn中为booster参数，在xgboost中为xgb_model。用于选择弱评估器，可以输入的值有：gbtree、gblinear和dart。<strong>gbtree</strong>为梯度提升树，<strong>gblinear</strong>为线性模型，<strong>dart</strong>为抛弃提升树，比梯度提升树有更好的放过拟合功能。在xgboost中必须用param传入参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> booster <span class="keyword">in</span> [<span class="string">&quot;gbtree&quot;</span>,<span class="string">&quot;gblinear&quot;</span>,<span class="string">&quot;dart&quot;</span>]:</span><br><span class="line">    reg = XGBR(n_estimators=<span class="number">190</span></span><br><span class="line">               ,subsample=<span class="number">0.9479166666666666</span></span><br><span class="line">               ,learning_rate=<span class="number">0.1</span></span><br><span class="line">               ,random_state=<span class="number">420</span>               </span><br><span class="line">               ,booster=booster).fit(Xtrain,Ytrain)</span><br><span class="line">    <span class="built_in">print</span>(booster)</span><br><span class="line">    <span class="built_in">print</span>(reg.score(Xtest,Ytest))</span><br></pre></td></tr></table></figure>

<pre><code>gbtree
0.9199261332157886
gblinear
0.6518219184964559
dart
0.9261191829728914
</code></pre>
<h2 id="目标函数：objective"><a href="#目标函数：objective" class="headerlink" title="目标函数：objective"></a>目标函数：objective<br></h2><p>$ ~~~~~~~ $在xgboost中使用目标函数来替代传统损失函数。xgb的目标函数可以写为：<strong>损失函数+模型复杂度</strong>。<br><br>$ ~~~~~~~~~~~~~~~~~~~ $ $Obj &#x3D; \sum_{i&#x3D;1}^m l(y_i , y_i’) + \sum_{k&#x3D;1}^K \Omega(f_k)$</p>
<p>$ ~~~~~~~ $第一项为损失函数，用来评估模型准确度。第二项为模型复杂度和树结构复杂度有直接联系，运用此函数添加在损失函数之后，可以使模型在准确的同时用最少的运算时间。当两者都最小，则平衡了模型效果和工程能力，使XGBoost运算又快又准。<br><br>$ ~~~~~~~ $方差用于评估模型稳定性，偏差用于评估模型的准确率。对应此目标函数。第一项衡量的是偏差，第二项则衡量方差。所以此目标函数也表示方差偏差平衡，也就是泛化误差。<br><br><br>$ ~~~~~~~ $对于xgboost，可以选择第一项的使用函数。在xgboost中参数为obj(也可以写成object)，在sklearn中为objective。在<strong>xgb.train()</strong> 和<strong>xgb.XGBClassifier()</strong> 中默认为 <strong>binary:logistic</strong>，在<strong>xgb.XGBRegressor()</strong> 中默认为 <strong>reg:linear</strong> 。</p>
<p>常用的参数有：<br></p>
<table>
<thead>
<tr>
<th align="center">输入</th>
<th align="center">使用的损失函数</th>
</tr>
</thead>
<tbody><tr>
<td align="center">reg:linear</td>
<td align="center">使用线性回归的损失函数，均方误差，回归时使用</td>
</tr>
<tr>
<td align="center">binary:logistic</td>
<td align="center">使用逻辑回归的损失函数，对数损失log_loss,二分类时使用</td>
</tr>
<tr>
<td align="center">binary:hinge</td>
<td align="center">使用支持向量机的损失函数，Hinge Loss，二分类时使用</td>
</tr>
<tr>
<td align="center">multi:softmax</td>
<td align="center">使用softmax损失函数，多分类时使用</td>
</tr>
</tbody></table>
<p><strong>现在推荐使用reg:squarederror来代替reg:linear。</strong><br><br>$ ~~~~~~~ $使用xgboost库来进行训练的流程：<br><br>$ xgb.DMatrix() -&gt; param&#x3D;{} -&gt; bst&#x3D;xgb.train(param) -&gt; bst.predict() $ <br><br> $ 读取数据-&gt;设置参数-&gt;训练模型-&gt;预测结果 $</p>
<h3 id="使用sklearn进行xgboost"><a href="#使用sklearn进行xgboost" class="headerlink" title="使用sklearn进行xgboost"></a>使用sklearn进行xgboost</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reg = XGBR(n_estimators=<span class="number">190</span>,random_state=<span class="number">420</span>,eta=<span class="number">0.1</span></span><br><span class="line">           ,subsample=<span class="number">0.9479166666666666</span>,booster=<span class="string">&quot;dart&quot;</span>).fit(Xtrain,Ytrain) </span><br><span class="line">reg.score(Xtest,Ytest) </span><br></pre></td></tr></table></figure>




<pre><code>0.9261191829728914
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MSE(Ytest,reg.predict(Xtest))</span><br></pre></td></tr></table></figure>




<pre><code>6.874897054416443
</code></pre>
<h3 id="使用xgboost库"><a href="#使用xgboost库" class="headerlink" title="使用xgboost库"></a>使用xgboost库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br></pre></td></tr></table></figure>

<h5 id="使用类DMatrix读取数据"><a href="#使用类DMatrix读取数据" class="headerlink" title="使用类DMatrix读取数据"></a>使用类DMatrix读取数据</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dtrain = xgb.DMatrix(Xtrain,Ytrain) <span class="comment"># 特征矩阵和标签都进行一个传入</span></span><br><span class="line">dtest = xgb.DMatrix(Xtest,Ytest)</span><br></pre></td></tr></table></figure>

<p>如果想要查看数据，可以在导入数据进入DMatrix之前在pandas中查看</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.DataFrame(Xtrain)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.03041</td>
      <td>0.0</td>
      <td>5.19</td>
      <td>0.0</td>
      <td>0.515</td>
      <td>5.895</td>
      <td>59.6</td>
      <td>5.6150</td>
      <td>5.0</td>
      <td>224.0</td>
      <td>20.2</td>
      <td>394.81</td>
      <td>10.56</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.04113</td>
      <td>25.0</td>
      <td>4.86</td>
      <td>0.0</td>
      <td>0.426</td>
      <td>6.727</td>
      <td>33.5</td>
      <td>5.4007</td>
      <td>4.0</td>
      <td>281.0</td>
      <td>19.0</td>
      <td>396.90</td>
      <td>5.29</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10.23300</td>
      <td>0.0</td>
      <td>18.10</td>
      <td>0.0</td>
      <td>0.614</td>
      <td>6.185</td>
      <td>96.7</td>
      <td>2.1705</td>
      <td>24.0</td>
      <td>666.0</td>
      <td>20.2</td>
      <td>379.70</td>
      <td>18.03</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.17142</td>
      <td>0.0</td>
      <td>6.91</td>
      <td>0.0</td>
      <td>0.448</td>
      <td>5.682</td>
      <td>33.8</td>
      <td>5.1004</td>
      <td>3.0</td>
      <td>233.0</td>
      <td>17.9</td>
      <td>396.90</td>
      <td>10.21</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.05059</td>
      <td>0.0</td>
      <td>4.49</td>
      <td>0.0</td>
      <td>0.449</td>
      <td>6.389</td>
      <td>48.0</td>
      <td>4.7794</td>
      <td>3.0</td>
      <td>247.0</td>
      <td>18.5</td>
      <td>396.90</td>
      <td>9.62</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>349</th>
      <td>0.03871</td>
      <td>52.5</td>
      <td>5.32</td>
      <td>0.0</td>
      <td>0.405</td>
      <td>6.209</td>
      <td>31.3</td>
      <td>7.3172</td>
      <td>6.0</td>
      <td>293.0</td>
      <td>16.6</td>
      <td>396.90</td>
      <td>7.14</td>
    </tr>
    <tr>
      <th>350</th>
      <td>0.12650</td>
      <td>25.0</td>
      <td>5.13</td>
      <td>0.0</td>
      <td>0.453</td>
      <td>6.762</td>
      <td>43.4</td>
      <td>7.9809</td>
      <td>8.0</td>
      <td>284.0</td>
      <td>19.7</td>
      <td>395.58</td>
      <td>9.50</td>
    </tr>
    <tr>
      <th>351</th>
      <td>6.96215</td>
      <td>0.0</td>
      <td>18.10</td>
      <td>0.0</td>
      <td>0.700</td>
      <td>5.713</td>
      <td>97.0</td>
      <td>1.9265</td>
      <td>24.0</td>
      <td>666.0</td>
      <td>20.2</td>
      <td>394.43</td>
      <td>17.11</td>
    </tr>
    <tr>
      <th>352</th>
      <td>0.09164</td>
      <td>0.0</td>
      <td>10.81</td>
      <td>0.0</td>
      <td>0.413</td>
      <td>6.065</td>
      <td>7.8</td>
      <td>5.2873</td>
      <td>4.0</td>
      <td>305.0</td>
      <td>19.2</td>
      <td>390.91</td>
      <td>5.52</td>
    </tr>
    <tr>
      <th>353</th>
      <td>5.58107</td>
      <td>0.0</td>
      <td>18.10</td>
      <td>0.0</td>
      <td>0.713</td>
      <td>6.436</td>
      <td>87.9</td>
      <td>2.3158</td>
      <td>24.0</td>
      <td>666.0</td>
      <td>20.2</td>
      <td>100.19</td>
      <td>16.22</td>
    </tr>
  </tbody>
</table>
<p>354 rows × 13 columns</p>
</div>



<h4 id="写明参数"><a href="#写明参数" class="headerlink" title="写明参数"></a>写明参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">param = &#123;<span class="string">&#x27;objective&#x27;</span>:<span class="string">&#x27;reg:squarederror&#x27;</span></span><br><span class="line">         ,<span class="string">&#x27;eta&#x27;</span>:<span class="number">0.1</span></span><br><span class="line">         ,<span class="string">&#x27;booster&#x27;</span>:<span class="string">&#x27;dart&#x27;</span></span><br><span class="line">         ,<span class="string">&#x27;subsample&#x27;</span>:<span class="number">0.9479166666666666</span>&#125;</span><br><span class="line">num_round = <span class="number">190</span> <span class="comment"># n_estimators</span></span><br></pre></td></tr></table></figure>

<h4 id="类train，可以直接导入的参数是训练数据，树的数量，其他参数都需要通过params来导入"><a href="#类train，可以直接导入的参数是训练数据，树的数量，其他参数都需要通过params来导入" class="headerlink" title="类train，可以直接导入的参数是训练数据，树的数量，其他参数都需要通过params来导入"></a>类train，可以直接导入的参数是训练数据，树的数量，其他参数都需要通过params来导入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bst = xgb.train(param, dtrain, num_round)</span><br></pre></td></tr></table></figure>

<h4 id="使用接口"><a href="#使用接口" class="headerlink" title="使用接口"></a>使用接口</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">preds = bst.predict(dtest)</span><br></pre></td></tr></table></figure>

<h4 id="导入sklearn库进行R方和均方误差评估"><a href="#导入sklearn库进行R方和均方误差评估" class="headerlink" title="导入sklearn库进行R方和均方误差评估"></a>导入sklearn库进行R方和均方误差评估</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2_score(Ytest,preds)</span><br></pre></td></tr></table></figure>




<pre><code>0.9264166709056179
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MSE(Ytest,preds)</span><br></pre></td></tr></table></figure>




<pre><code>6.8472146465232635
</code></pre>
<p>通过对比发现xgboost库本身是优于sklearn库里xgboost的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
</div></section><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author: </strong>w_pl</li><li class="post-copyright-link"><strong>Post link: </strong><a href="https://wplll.github.io/2022/10/25/XGBoost/" title="XGBoost实战">https://wplll.github.io/2022/10/25/XGBoost/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/deed.zh" target="_blank" rel="noopener" title="CC ZERO 1.0 "><span class="icon iconify" data-icon="ri:creative-commons-line"></span><span class="icon iconify" data-icon="ri:creative-commons-zero-line"></span></a> unless otherwise stated.</li></ul></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2022/10/25/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/" rel="prev" title="搭建一个自己的网站"><span class="icon iconify" data-icon="ri:arrow-left-s-line"></span><span class="post-nav-text">搭建一个自己的网站</span></a></div><div class="post-nav-item"></div></div></div><div class="hty-card" id="comment"></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2022 </span><span class="with-love" id="animate"><span class="icon iconify" data-icon="ri:cloud-line"></span></span><span class="author"> w_pl</span></div><div class="powered"><span>Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> v5.4.2</span><span class="footer-separator">|</span><span>Theme - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.10.9</span></div><div class="live-time"><span>本博客已运行</span><span id="display_live_time"></span><span class="moe-text">(●'◡'●)</span><script>function blog_live_time() {
  setTimeout(blog_live_time, 1000);
  const start = new Date('2022-05-26T00:00:00');
  const now = new Date();
  const timeDiff = (now.getTime() - start.getTime());
  const msPerMinute = 60 * 1000;
  const msPerHour = 60 * msPerMinute;
  const msPerDay = 24 * msPerHour;
  const passDay = Math.floor(timeDiff / msPerDay);
  const passHour = Math.floor((timeDiff % msPerDay) / 60 / 60 / 1000);
  const passMinute = Math.floor((timeDiff % msPerHour) / 60 / 1000);
  const passSecond = Math.floor((timeDiff % msPerMinute) / 1000);
  display_live_time.innerHTML = ` ${passDay} Days ${passHour} Hours ${passMinute} Minutes ${passSecond} Seconds`;
}
blog_live_time();
</script></div><div class="footer-support"><span>本网站由</span><a class="footer-support-logo" href="https://www.upyun.com/?utm_source=lianmeng&amp;utm_medium=referral" target="blank" title="又拍云"><img height="30" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/logo/upyun-logo.png" alt="又拍云"></a><span>提供 CDN 加速</span></div></footer></div><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><span class="icon iconify" data-icon="ri:arrow-up-s-line"></span><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><script>function initMourn() {
  const date = new Date();
  const today = (date.getMonth() + 1) + "-" + date.getDate()
  const mourn_days = ["4-4","9-18"]
  if (mourn_days.includes(today)) {
    document.documentElement.style.filter = "grayscale(1)";
  }
}
initMourn();</script></body></html>